#!/usr/bin/env python3
"""
VIGIA Medical AI - Comprehensive Hume AI Testing Suite
====================================================

Test suite for validating Hume AI voice analysis capabilities with medical focus.
Tests pain detection, distress analysis, and integration with Batman tokenization.
"""

import asyncio
import os
import sys
import tempfile
import wave
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import logging

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import Hume AI client
from src.ai.hume_ai_client import HumeAIClient, create_hume_ai_client
from src.core.phi_tokenization_client import PHITokenizationClient

async def generate_test_audio(text: str, emotion: str = "neutral", duration: float = 3.0) -> bytes:
    """
    Generate synthetic test audio for Hume AI testing.
    
    Args:
        text: Text content for audio
        emotion: Emotion to simulate
        duration: Audio duration in seconds
        
    Returns:
        Audio bytes in WAV format
    """
    # Generate synthetic audio (sine wave with variations for emotion simulation)
    sample_rate = 16000
    samples = int(sample_rate * duration)
    
    # Base frequency varies by emotion
    emotion_frequencies = {
        "neutral": 440.0,
        "pain": 380.0,     # Lower, strained
        "distress": 460.0, # Higher, anxious
        "fear": 480.0,     # High, trembling
        "calm": 420.0      # Stable, lower
    }
    
    base_freq = emotion_frequencies.get(emotion, 440.0)
    
    # Generate audio signal
    t = np.linspace(0, duration, samples, False)
    
    # Add emotion-specific modulations
    if emotion == "pain":
        # Irregular, strained pattern
        signal = np.sin(2 * np.pi * base_freq * t) * (0.7 + 0.3 * np.sin(2 * np.pi * 2 * t))
        signal += 0.1 * np.random.normal(0, 1, samples)  # Add strain noise
    elif emotion == "distress":
        # Rapid variations, higher pitch
        signal = np.sin(2 * np.pi * base_freq * t) * (0.8 + 0.4 * np.sin(2 * np.pi * 5 * t))
        signal += 0.05 * np.sin(2 * np.pi * base_freq * 1.5 * t)  # Harmony
    elif emotion == "fear":
        # Trembling, unstable
        trembling = 1 + 0.2 * np.sin(2 * np.pi * 8 * t)  # 8Hz trembling
        signal = np.sin(2 * np.pi * base_freq * t) * trembling
        signal += 0.15 * np.random.normal(0, 1, samples)  # Anxiety noise
    else:
        # Neutral/calm
        signal = np.sin(2 * np.pi * base_freq * t) * 0.8
    
    # Normalize and convert to 16-bit PCM
    signal = np.clip(signal, -1, 1)
    audio_data = (signal * 32767).astype(np.int16)
    
    # Create WAV file in memory
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
        with wave.open(temp_wav.name, 'wb') as wav_file:
            wav_file.setnchannels(1)  # Mono
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_data.tobytes())
        
        # Read back as bytes
        with open(temp_wav.name, 'rb') as f:
            audio_bytes = f.read()
        
        # Cleanup
        os.unlink(temp_wav.name)
        
        return audio_bytes

async def test_hume_ai_connection():
    """Test basic Hume AI API connection"""
    print("üîó Testing Hume AI API connection...")
    
    try:
        # Create client with API key from environment
        client = create_hume_ai_client()
        print("‚úÖ Hume AI client created successfully")
        
        # Test with simple audio
        test_audio = await generate_test_audio("Hello, this is a test", "neutral")
        print(f"‚úÖ Generated test audio: {len(test_audio)} bytes")
        
        # Create mock Batman token for testing
        token_client = PHITokenizationClient()
        batman_token = await token_client.create_token_async(
            hospital_mrn="TEST_001",
            patient_data={"test": "hume_ai_validation"}
        )
        print(f"‚úÖ Created Batman token: {batman_token}")
        
        return True, client, batman_token
        
    except Exception as e:
        print(f"‚ùå Hume AI connection failed: {e}")
        return False, None, None

async def test_pain_detection():
    """Test pain detection capabilities"""
    print("\\nü©∫ Testing pain detection...")
    
    try:
        success, client, batman_token = await test_hume_ai_connection()
        if not success:
            return False
        
        # Generate pain-simulated audio
        pain_audio = await generate_test_audio(
            "My knee hurts so much, I can barely walk", 
            "pain", 
            duration=4.0
        )
        
        # Analyze with Hume AI
        result = await client.analyze_voice_expressions(
            audio_data=pain_audio,
            token_id=batman_token,
            patient_context={
                "medical_condition": "knee_pain",
                "test_scenario": "pain_detection"
            }
        )
        
        print(f"‚úÖ Pain analysis completed")
        print(f"   Analysis ID: {result.analysis_id}")
        print(f"   Pain Score: {result.medical_indicators.pain_score:.3f}")
        print(f"   Stress Level: {result.medical_indicators.stress_level:.3f}")
        print(f"   Alert Level: {result.medical_indicators.alert_level}")
        print(f"   Confidence: {result.confidence_level:.3f}")
        
        # Validate pain detection
        if result.medical_indicators.pain_score > 0.3:
            print("‚úÖ Pain detection working - elevated pain score detected")
        else:
            print("‚ö†Ô∏è Pain detection may need calibration - low pain score")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Pain detection test failed: {e}")
        return False

async def test_distress_analysis():
    """Test distress and anxiety analysis"""
    print("\\nüò∞ Testing distress analysis...")
    
    try:
        success, client, batman_token = await test_hume_ai_connection()
        if not success:
            return False
        
        # Generate distress-simulated audio
        distress_audio = await generate_test_audio(
            "I'm so worried about my condition, I can't sleep", 
            "distress", 
            duration=5.0
        )
        
        # Analyze with Hume AI
        result = await client.analyze_voice_expressions(
            audio_data=distress_audio,
            token_id=batman_token,
            patient_context={
                "medical_condition": "anxiety_assessment",
                "test_scenario": "distress_detection"
            }
        )
        
        print(f"‚úÖ Distress analysis completed")
        print(f"   Emotional Distress: {result.medical_indicators.emotional_distress:.3f}")
        print(f"   Anxiety Indicators: {result.medical_indicators.anxiety_indicators:.3f}")
        print(f"   Alert Level: {result.medical_indicators.alert_level}")
        print(f"   Recommendations: {len(result.medical_indicators.medical_recommendations)}")
        
        # Show specific emotions detected
        if result.expressions:
            print("   Top Emotions Detected:")
            sorted_emotions = sorted(result.expressions.items(), key=lambda x: x[1], reverse=True)
            for emotion, score in sorted_emotions[:5]:
                print(f"     {emotion}: {score:.3f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Distress analysis test failed: {e}")
        return False

async def test_emotional_range():
    """Test detection across emotional range"""
    print("\\nüé≠ Testing emotional range detection...")
    
    try:
        success, client, batman_token = await test_hume_ai_connection()
        if not success:
            return False
        
        emotions_to_test = [
            ("calm", "I feel relaxed and comfortable today"),
            ("fear", "I'm scared about the upcoming surgery"),
            ("pain", "This wound is causing me severe discomfort"),
            ("distress", "I'm overwhelmed and don't know what to do")
        ]
        
        results = {}
        
        for emotion, text in emotions_to_test:
            print(f"   Testing {emotion}...")
            
            # Generate audio for this emotion
            audio = await generate_test_audio(text, emotion, duration=3.0)
            
            # Analyze
            result = await client.analyze_voice_expressions(
                audio_data=audio,
                token_id=batman_token,
                patient_context={
                    "test_emotion": emotion,
                    "test_scenario": "emotional_range"
                }
            )
            
            results[emotion] = {
                "pain_score": result.medical_indicators.pain_score,
                "stress_level": result.medical_indicators.stress_level,
                "emotional_distress": result.medical_indicators.emotional_distress,
                "alert_level": result.medical_indicators.alert_level,
                "top_emotions": dict(sorted(result.expressions.items(), key=lambda x: x[1], reverse=True)[:3])
            }
            
            print(f"     Pain: {result.medical_indicators.pain_score:.3f}, "
                  f"Stress: {result.medical_indicators.stress_level:.3f}, "
                  f"Alert: {result.medical_indicators.alert_level}")
        
        print("\\n‚úÖ Emotional range analysis completed")
        
        # Validate emotional differentiation
        if (results["pain"]["pain_score"] > results["calm"]["pain_score"] and
            results["distress"]["emotional_distress"] > results["calm"]["emotional_distress"]):
            print("‚úÖ Emotional differentiation working correctly")
        else:
            print("‚ö†Ô∏è Emotional differentiation may need calibration")
        
        return True, results
        
    except Exception as e:
        print(f"‚ùå Emotional range test failed: {e}")
        return False, {}

async def test_medical_recommendations():
    """Test medical recommendation generation"""
    print("\\nüíä Testing medical recommendations...")
    
    try:
        success, client, batman_token = await test_hume_ai_connection()
        if not success:
            return False
        
        # Test high-severity case
        severe_audio = await generate_test_audio(
            "The pain is unbearable, I need help immediately", 
            "pain", 
            duration=4.0
        )
        
        result = await client.analyze_voice_expressions(
            audio_data=severe_audio,
            token_id=batman_token,
            patient_context={
                "chronic_pain": True,
                "medical_condition": "pressure_injury_grade_3",
                "test_scenario": "severe_pain"
            }
        )
        
        print(f"‚úÖ Medical recommendations generated: {len(result.medical_indicators.medical_recommendations)}")
        print("   Recommendations:")
        for i, rec in enumerate(result.medical_indicators.medical_recommendations, 1):
            print(f"     {i}. {rec}")
        
        # Validate critical case handling
        if result.medical_indicators.alert_level in ["high", "critical"]:
            print("‚úÖ Critical case detection working")
        else:
            print("‚ö†Ô∏è Critical case detection may need adjustment")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Medical recommendations test failed: {e}")
        return False

async def test_batman_tokenization_integration():
    """Test integration with Batman tokenization system"""
    print("\\nü¶á Testing Batman tokenization integration...")
    
    try:
        # Test multiple patient scenarios
        scenarios = [
            {"mrn": "PATIENT_001", "condition": "pressure_injury_monitoring"},
            {"mrn": "PATIENT_002", "condition": "post_surgical_pain"},
            {"mrn": "PATIENT_003", "condition": "chronic_wound_care"}
        ]
        
        token_client = PHITokenizationClient()
        client = create_hume_ai_client()
        
        for scenario in scenarios:
            # Create Batman token
            batman_token = await token_client.create_token_async(
                hospital_mrn=scenario["mrn"],
                patient_data=scenario
            )
            
            # Generate test audio
            audio = await generate_test_audio(
                f"I need help with my {scenario['condition'].replace('_', ' ')}", 
                "pain"
            )
            
            # Analyze with Hume AI
            result = await client.analyze_voice_expressions(
                audio_data=audio,
                token_id=batman_token,
                patient_context=scenario
            )
            
            print(f"   ‚úÖ {scenario['mrn']}: Token {batman_token}, Analysis {result.analysis_id}")
        
        print("‚úÖ Batman tokenization integration working")
        return True
        
    except Exception as e:
        print(f"‚ùå Batman tokenization test failed: {e}")
        return False

async def test_raw_outputs_capture():
    """Test raw outputs capture for research"""
    print("\\nüìä Testing raw outputs capture...")
    
    try:
        success, client, batman_token = await test_hume_ai_connection()
        if not success:
            return False
        
        # Generate test audio
        audio = await generate_test_audio(
            "This is for research data capture testing", 
            "neutral"
        )
        
        # Analyze and capture raw outputs
        result = await client.analyze_voice_expressions(
            audio_data=audio,
            token_id=batman_token,
            patient_context={
                "research_consent": True,
                "test_scenario": "raw_outputs_capture"
            }
        )
        
        # Check raw outputs
        if result.raw_outputs:
            print("‚úÖ Raw outputs captured successfully")
            print(f"   Model metadata keys: {list(result.raw_outputs.model_metadata.keys())}")
            print(f"   Processing metadata: {len(result.raw_outputs.processing_metadata)} fields")
            if result.raw_outputs.compressed_size:
                print(f"   Compressed size: {result.raw_outputs.compressed_size} bytes")
        else:
            print("‚ö†Ô∏è Raw outputs not captured")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Raw outputs capture test failed: {e}")
        return False

async def main():
    """Run comprehensive Hume AI test suite"""
    print("ü©∫ VIGIA Medical AI - Hume AI Comprehensive Testing")
    print("=" * 65)
    print("Testing voice analysis capabilities for medical applications")
    print("=" * 65)
    
    # Check API key
    api_key = os.getenv("HUME_AI_API_KEY")
    if not api_key:
        print("‚ùå HUME_AI_API_KEY not found in environment")
        print("   Please set the API key in .env file")
        return False
    
    print(f"üîë API Key configured: {api_key[:20]}...")
    
    # Run all tests
    tests = [
        ("API Connection", test_hume_ai_connection),
        ("Pain Detection", test_pain_detection),
        ("Distress Analysis", test_distress_analysis),
        ("Emotional Range", test_emotional_range),
        ("Medical Recommendations", test_medical_recommendations),
        ("Batman Tokenization", test_batman_tokenization_integration),
        ("Raw Outputs Capture", test_raw_outputs_capture)
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for test_name, test_func in tests:
        print(f"\\nüî¨ Running: {test_name}")
        try:
            if test_name == "API Connection":
                # Skip duplicate connection test
                result = True
            else:
                result = await test_func()
            
            if result:
                passed_tests += 1
                print(f"‚úÖ {test_name}: PASSED")
            else:
                print(f"‚ùå {test_name}: FAILED")
        except Exception as e:
            print(f"‚ùå {test_name}: ERROR - {e}")
    
    print("\\n" + "=" * 65)
    print(f"üèÜ FINAL RESULTS: {passed_tests}/{total_tests} tests passed")
    
    if passed_tests == total_tests:
        print("üéâ All tests passed! Hume AI is ready for medical use.")
        success_rate = 100
    else:
        success_rate = (passed_tests / total_tests) * 100
        print(f"‚ö†Ô∏è  {success_rate:.1f}% success rate - some components need attention")
    
    # Generate test report
    test_report = {
        "test_suite": "hume_ai_comprehensive",
        "timestamp": datetime.now().isoformat(),
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "success_rate": f"{success_rate:.1f}%",
        "api_key_configured": bool(api_key),
        "medical_voice_analysis_ready": passed_tests >= 5,
        "production_ready": passed_tests == total_tests
    }
    
    # Save test report
    report_path = project_root / "hume_ai_test_report.json"
    with open(report_path, 'w') as f:
        json.dump(test_report, f, indent=2)
    
    print(f"üìÑ Test report saved to: {report_path}")
    
    return passed_tests == total_tests

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)