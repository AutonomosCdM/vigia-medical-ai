"""
MONAI Review Agent - Specialized Medical AI Output Analysis
==========================================================

ADK agent specialized in analyzing raw MONAI outputs to generate detailed
medical reports and quality assessments for research and validation.

Key Features:
- Raw MONAI output decompression and analysis
- Medical-grade segmentation mask interpretation
- Confidence map detailed analysis
- Model performance assessment
- Research-grade validation reports
- A2A communication for collaborative analysis

Usage:
    agent = MonaiReviewAgent()
    review_result = await agent.analyze_monai_outputs(raw_output_id, analysis_context)
"""

import asyncio
import logging
import json
import gzip
import base64
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass
from enum import Enum

from src.agents.base_agent import BaseAgent, AgentMessage, AgentResponse
from src.db.raw_outputs_client import RawOutputsClient
from src.db.supabase_client import SupabaseClient
from src.utils.audit_service import AuditService
from src.systems.medical_knowledge import MedicalKnowledgeSystem

# AgentOps Monitoring Integration
from src.monitoring.agentops_client import AgentOpsClient
from src.monitoring.medical_telemetry import MedicalTelemetry
from src.monitoring.adk_wrapper import adk_agent_wrapper

logger = logging.getLogger(__name__)


class ModelPerformanceLevel(Enum):
    """Model performance assessment levels"""
    EXCELLENT = "excellent"
    GOOD = "good"
    ACCEPTABLE = "acceptable"
    CONCERNING = "concerning"
    POOR = "poor"


class SegmentationQuality(Enum):
    """Segmentation quality assessment"""
    PRECISE = "precise"
    GOOD = "good"
    MODERATE = "moderate"
    POOR = "poor"
    INVALID = "invalid"


@dataclass
class ConfidenceAnalysis:
    """Detailed confidence map analysis"""
    mean_confidence: float
    max_confidence: float
    min_confidence: float
    confidence_std: float
    high_confidence_regions: int
    low_confidence_regions: int
    confidence_distribution: Dict[str, float]  # percentiles
    uncertainty_areas: List[Dict[str, Any]]


@dataclass
class SegmentationAnalysis:
    """Detailed segmentation analysis"""
    detected_regions: int
    total_segmented_pixels: int
    largest_region_size: int
    average_region_size: float
    segmentation_quality: str
    anatomical_coherence: str
    edge_sharpness: float
    region_connectivity: Dict[str, Any]


@dataclass
class ModelAssessment:
    """Comprehensive model performance assessment"""
    model_version: str
    model_architecture: str
    performance_level: str
    prediction_confidence: float
    processing_quality: str
    medical_validity: str
    technical_score: float
    clinical_score: float
    research_value: str


@dataclass
class MonaiReviewResult:
    """Complete MONAI review analysis result"""
    review_id: str
    raw_output_id: str
    token_id: str  # Batman token
    model_assessment: ModelAssessment
    confidence_analysis: ConfidenceAnalysis
    segmentation_analysis: SegmentationAnalysis
    medical_interpretation: Dict[str, Any]
    quality_metrics: Dict[str, float]
    validation_findings: List[str]
    research_insights: List[str]
    technical_recommendations: List[str]
    review_timestamp: datetime
    reviewer_agent: str
    hipaa_compliant: bool = True


class MonaiReviewAgent(BaseAgent):
    """
    Specialized agent for analyzing raw MONAI outputs and generating
    comprehensive medical and technical review reports.
    
    Capabilities:
    - Raw MONAI output decompression and parsing
    - Confidence map statistical analysis
    - Segmentation mask quality assessment
    - Medical validity evaluation
    - Research insight generation
    - Technical performance review
    """
    
    def __init__(self, agent_id: str = "monai_review_agent"):
        super().__init__(agent_id=agent_id, agent_type="monai_review")
        
        self.raw_outputs_client = RawOutputsClient()
        self.supabase = SupabaseClient()
        self.audit_service = AuditService()
        self.medical_knowledge = MedicalKnowledgeSystem()
        
        # Analysis thresholds based on medical research
        self.quality_thresholds = {
            'high_confidence': 0.8,
            'acceptable_confidence': 0.6,
            'min_segmentation_size': 100,  # pixels
            'max_edge_variance': 0.3,
            'min_anatomical_coherence': 0.7
        }
        
        # Review statistics
        self.stats = {
            'reviews_completed': 0,
            'excellent_performance_cases': 0,
            'concerning_cases': 0,
            'research_insights_generated': 0,
            'technical_issues_identified': 0,
            'avg_review_time': 0.0
        }
        
        # AgentOps telemetry integration
        self.telemetry = MedicalTelemetry(
            agent_id=self.agent_id,
            agent_type="monai_review"
        )
    
    async def initialize(self) -> bool:
        """Initialize the MONAI review agent"""
        try:
            # Test raw outputs client connection
            if self.raw_outputs_client:
                logger.info("MONAI Review Agent initialized with raw outputs access")
            else:
                logger.warning("MONAI Review Agent initialized without raw outputs access")
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize MONAI Review Agent: {e}")
            return False
    
    def get_capabilities(self) -> List[str]:
        """Get agent capabilities"""
        return [
            "raw_monai_output_analysis",
            "confidence_map_analysis", 
            "segmentation_mask_review",
            "model_performance_assessment",
            "medical_validity_evaluation",
            "research_insight_generation",
            "technical_quality_review",
            "statistical_analysis",
            "comparative_performance_analysis",
            "batman_tokenization_support",
            "medical_grade_validation"
        ]
    
    async def process_message(self, message: AgentMessage) -> AgentResponse:
        """Process incoming agent messages"""
        try:
            action = message.action
            
            if action == "analyze_monai_outputs":
                return await self._handle_monai_analysis(message)
            elif action == "assess_model_performance":
                return await self._handle_performance_assessment(message)
            elif action == "analyze_confidence_maps":
                return await self._handle_confidence_analysis(message)
            elif action == "review_segmentation_quality":
                return await self._handle_segmentation_review(message)
            elif action == "generate_research_insights":
                return await self._handle_research_insights(message)
            elif action == "validate_medical_accuracy":
                return await self._handle_medical_validation(message)
            elif action == "get_review_capabilities":
                return await self._handle_capabilities_request(message)
            else:
                return AgentResponse(
                    success=False,
                    message=f"Unknown action: {action}",
                    data={}
                )
                
        except Exception as e:
            logger.error(f"Error processing message in MONAI Review Agent: {e}")
            return AgentResponse(
                success=False,
                message=f"Processing error: {str(e)}",
                data={}
            )
    
    async def _handle_monai_analysis(self, message: AgentMessage) -> AgentResponse:
        """Handle complete MONAI output analysis requests"""
        try:
            start_time = datetime.now()
            
            # Extract parameters
            raw_output_id = message.data.get("raw_output_id")
            analysis_context = message.data.get("analysis_context", {})
            review_depth = message.data.get("review_depth", "comprehensive")
            
            if not raw_output_id:
                return AgentResponse(
                    success=False,
                    message="Missing required parameter: raw_output_id",
                    data={}
                )
            
            # Perform comprehensive MONAI analysis
            result = await self.analyze_monai_outputs(raw_output_id, analysis_context, review_depth)
            
            # Update statistics
            processing_time = (datetime.now() - start_time).total_seconds()
            await self._update_review_stats(processing_time, result)
            
            return AgentResponse(
                success=True,
                message="MONAI output analysis completed successfully",
                data={
                    "review_result": self._serialize_review_result(result),
                    "raw_output_id": raw_output_id,
                    "processing_time_seconds": processing_time,
                    "hipaa_compliant": True
                }
            )
            
        except Exception as e:
            logger.error(f"MONAI analysis failed: {e}")
            return AgentResponse(
                success=False,
                message=f"MONAI analysis failed: {str(e)}",
                data={}
            )
    
    async def analyze_monai_outputs(
        self,
        raw_output_id: str,
        analysis_context: Dict[str, Any],
        review_depth: str = "comprehensive"
    ) -> MonaiReviewResult:
        """
        Perform comprehensive analysis of raw MONAI outputs.
        
        Args:
            raw_output_id: ID of raw MONAI output to analyze
            analysis_context: Medical and technical context for analysis
            review_depth: Depth of analysis ("rapid", "standard", "comprehensive")
            
        Returns:
            Complete MONAI review analysis result
        """
        try:
            # Generate review ID
            review_id = f"monai_review_{raw_output_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Retrieve raw MONAI output data
            raw_output_data = await self._get_raw_monai_data(raw_output_id)
            
            if not raw_output_data:
                raise ValueError(f"Raw MONAI output not found: {raw_output_id}")
            
            # Extract token_id for HIPAA compliance
            token_id = raw_output_data.get("token_id", "unknown")
            
            # Decompress and parse MONAI data
            parsed_data = await self._parse_monai_raw_data(raw_output_data)
            
            # Comprehensive model assessment
            model_assessment = await self._assess_model_performance(parsed_data, analysis_context)
            
            # Confidence analysis
            confidence_analysis = await self._analyze_confidence_maps(parsed_data)
            
            # Segmentation analysis
            segmentation_analysis = await self._analyze_segmentation_masks(parsed_data)
            
            # Medical interpretation
            medical_interpretation = await self._interpret_medical_findings(
                parsed_data, model_assessment, analysis_context
            )
            
            # Quality metrics calculation
            quality_metrics = await self._calculate_quality_metrics(
                model_assessment, confidence_analysis, segmentation_analysis
            )
            
            # Validation findings
            validation_findings = await self._generate_validation_findings(
                parsed_data, model_assessment, medical_interpretation
            )
            
            # Research insights
            research_insights = await self._generate_research_insights(
                parsed_data, model_assessment, analysis_context
            )
            
            # Technical recommendations
            technical_recommendations = await self._generate_technical_recommendations(
                model_assessment, confidence_analysis, segmentation_analysis
            )
            
            # Create comprehensive result
            result = MonaiReviewResult(
                review_id=review_id,
                raw_output_id=raw_output_id,
                token_id=token_id,
                model_assessment=model_assessment,
                confidence_analysis=confidence_analysis,
                segmentation_analysis=segmentation_analysis,
                medical_interpretation=medical_interpretation,
                quality_metrics=quality_metrics,
                validation_findings=validation_findings,
                research_insights=research_insights,
                technical_recommendations=technical_recommendations,
                review_timestamp=datetime.now(),
                reviewer_agent=self.agent_id,
                hipaa_compliant=True
            )
            
            # Store review result
            await self._store_monai_review(result)
            
            # Log review for audit trail
            await self.audit_service.log_event(
                event_type="monai_review_completed",
                component="monai_review_agent",
                action="analyze_monai_outputs",
                details={
                    "review_id": review_id,
                    "raw_output_id": raw_output_id,
                    "token_id": token_id,
                    "performance_level": model_assessment.performance_level,
                    "technical_score": model_assessment.technical_score,
                    "clinical_score": model_assessment.clinical_score,
                    "research_insights_count": len(research_insights)
                }
            )
            
            return result
            
        except Exception as e:
            logger.error(f"MONAI output analysis failed: {e}")
            raise
    
    async def _get_raw_monai_data(self, raw_output_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve raw MONAI output data from database"""
        try:
            if not self.supabase.client:
                logger.warning("No database connection available")
                return None
            
            # Query ai_raw_outputs table for MONAI data
            result = self.supabase.client.table("ai_raw_outputs").select("*").eq("output_id", raw_output_id).eq("ai_engine", "monai").execute()
            
            if result.data:
                return result.data[0]
            else:
                logger.warning(f"No MONAI raw output found for ID: {raw_output_id}")
                return None
                
        except Exception as e:
            logger.error(f"Failed to retrieve raw MONAI data: {e}")
            return None
    
    async def _parse_monai_raw_data(self, raw_output_data: Dict[str, Any]) -> Dict[str, Any]:
        """Parse and decompress raw MONAI output data"""
        try:
            parsed_data = {
                "raw_predictions": raw_output_data.get("raw_output"),
                "model_metadata": raw_output_data.get("monai_metadata", {}),
                "processing_metadata": raw_output_data.get("input_characteristics", {}),
                "confidence_maps": None,
                "detection_arrays": None
            }
            
            # Decompress confidence maps if available
            if raw_output_data.get("confidence_maps"):
                confidence_maps_b64 = raw_output_data["confidence_maps"]
                confidence_maps_compressed = base64.b64decode(confidence_maps_b64)
                confidence_maps_bytes = gzip.decompress(confidence_maps_compressed)
                
                # Reconstruct numpy array from metadata
                shape = parsed_data["processing_metadata"].get("prediction_shape", (1, 5, 512, 512))
                dtype = parsed_data["processing_metadata"].get("prediction_dtype", "float32")
                
                confidence_maps = np.frombuffer(confidence_maps_bytes, dtype=dtype)
                parsed_data["confidence_maps"] = confidence_maps.reshape(shape)
            
            # Decompress detection arrays if available  
            if raw_output_data.get("detection_arrays"):
                detection_arrays_b64 = raw_output_data["detection_arrays"]
                detection_arrays_compressed = base64.b64decode(detection_arrays_b64)
                detection_arrays_bytes = gzip.decompress(detection_arrays_compressed)
                
                detection_arrays = np.frombuffer(detection_arrays_bytes, dtype="float32")
                parsed_data["detection_arrays"] = detection_arrays
            
            return parsed_data
            
        except Exception as e:
            logger.error(f"Failed to parse MONAI raw data: {e}")
            raise
    
    async def _assess_model_performance(self, parsed_data: Dict[str, Any], analysis_context: Dict[str, Any]) -> ModelAssessment:
        """Assess MONAI model performance comprehensively"""
        
        model_metadata = parsed_data.get("model_metadata", {})
        raw_predictions = parsed_data.get("raw_predictions", [])
        confidence_maps = parsed_data.get("confidence_maps")
        
        # Extract model information
        model_version = model_metadata.get("model_version", "unknown")
        model_architecture = model_metadata.get("model_architecture", "densenet121")
        
        # Calculate prediction confidence
        if isinstance(raw_predictions, list) and raw_predictions:
            if isinstance(raw_predictions[0], list):
                # Softmax probabilities
                max_prediction = max(max(pred) if isinstance(pred, list) else pred for pred in raw_predictions)
                prediction_confidence = float(max_prediction)
            else:
                prediction_confidence = float(max(raw_predictions))
        else:
            prediction_confidence = 0.5
        
        # Assess technical quality
        technical_score = self._calculate_technical_score(parsed_data)
        
        # Assess clinical relevance
        clinical_score = self._calculate_clinical_score(parsed_data, analysis_context)
        
        # Determine performance level
        performance_level = self._determine_performance_level(prediction_confidence, technical_score, clinical_score)
        
        # Assess processing quality
        processing_quality = self._assess_processing_quality(parsed_data)
        
        # Assess medical validity
        medical_validity = self._assess_medical_validity(parsed_data, analysis_context)
        
        # Assess research value
        research_value = self._assess_research_value(parsed_data, technical_score, clinical_score)
        
        return ModelAssessment(
            model_version=model_version,
            model_architecture=model_architecture,
            performance_level=performance_level.value,
            prediction_confidence=prediction_confidence,
            processing_quality=processing_quality,
            medical_validity=medical_validity,
            technical_score=technical_score,
            clinical_score=clinical_score,
            research_value=research_value
        )
    
    async def _analyze_confidence_maps(self, parsed_data: Dict[str, Any]) -> ConfidenceAnalysis:
        """Analyze confidence maps in detail"""
        
        confidence_maps = parsed_data.get("confidence_maps")
        
        if confidence_maps is None:
            # Return mock analysis if no confidence maps
            return ConfidenceAnalysis(
                mean_confidence=0.5,
                max_confidence=0.5,
                min_confidence=0.5,
                confidence_std=0.0,
                high_confidence_regions=0,
                low_confidence_regions=0,
                confidence_distribution={"p25": 0.5, "p50": 0.5, "p75": 0.5, "p90": 0.5},
                uncertainty_areas=[]
            )
        
        try:
            # Statistical analysis
            flat_confidence = confidence_maps.flatten()
            mean_confidence = float(np.mean(flat_confidence))
            max_confidence = float(np.max(flat_confidence))
            min_confidence = float(np.min(flat_confidence))
            confidence_std = float(np.std(flat_confidence))
            
            # High and low confidence regions
            high_threshold = self.quality_thresholds['high_confidence']
            low_threshold = self.quality_thresholds['acceptable_confidence']
            
            high_confidence_regions = int(np.sum(flat_confidence >= high_threshold))
            low_confidence_regions = int(np.sum(flat_confidence < low_threshold))
            
            # Confidence distribution percentiles
            confidence_distribution = {
                "p25": float(np.percentile(flat_confidence, 25)),
                "p50": float(np.percentile(flat_confidence, 50)),
                "p75": float(np.percentile(flat_confidence, 75)),
                "p90": float(np.percentile(flat_confidence, 90)),
                "p95": float(np.percentile(flat_confidence, 95))
            }
            
            # Identify uncertainty areas (regions with high variance)
            uncertainty_areas = self._identify_uncertainty_areas(confidence_maps)
            
            return ConfidenceAnalysis(
                mean_confidence=mean_confidence,
                max_confidence=max_confidence,
                min_confidence=min_confidence,
                confidence_std=confidence_std,
                high_confidence_regions=high_confidence_regions,
                low_confidence_regions=low_confidence_regions,
                confidence_distribution=confidence_distribution,
                uncertainty_areas=uncertainty_areas
            )
            
        except Exception as e:
            logger.error(f"Failed to analyze confidence maps: {e}")
            # Return default analysis on error
            return ConfidenceAnalysis(
                mean_confidence=0.5,
                max_confidence=0.5,
                min_confidence=0.5,
                confidence_std=0.0,
                high_confidence_regions=0,
                low_confidence_regions=0,
                confidence_distribution={"p25": 0.5, "p50": 0.5, "p75": 0.5, "p90": 0.5},
                uncertainty_areas=[]
            )
    
    async def _analyze_segmentation_masks(self, parsed_data: Dict[str, Any]) -> SegmentationAnalysis:
        """Analyze segmentation mask quality"""
        
        confidence_maps = parsed_data.get("confidence_maps")
        detection_arrays = parsed_data.get("detection_arrays")
        
        if confidence_maps is None:
            # Return mock analysis if no segmentation data
            return SegmentationAnalysis(
                detected_regions=0,
                total_segmented_pixels=0,
                largest_region_size=0,
                average_region_size=0.0,
                segmentation_quality=SegmentationQuality.MODERATE.value,
                anatomical_coherence="unknown",
                edge_sharpness=0.0,
                region_connectivity={}
            )
        
        try:
            # Convert confidence maps to binary segmentation
            threshold = self.quality_thresholds['acceptable_confidence']
            binary_mask = confidence_maps > threshold
            
            # Count detected regions
            detected_regions = self._count_connected_regions(binary_mask)
            
            # Calculate segmented pixels
            total_segmented_pixels = int(np.sum(binary_mask))
            
            # Region size analysis
            region_sizes = self._analyze_region_sizes(binary_mask)
            largest_region_size = int(max(region_sizes)) if region_sizes else 0
            average_region_size = float(np.mean(region_sizes)) if region_sizes else 0.0
            
            # Assess segmentation quality
            segmentation_quality = self._assess_segmentation_quality(
                detected_regions, total_segmented_pixels, region_sizes
            )
            
            # Assess anatomical coherence
            anatomical_coherence = self._assess_anatomical_coherence(binary_mask, region_sizes)
            
            # Calculate edge sharpness
            edge_sharpness = self._calculate_edge_sharpness(confidence_maps)
            
            # Analyze region connectivity
            region_connectivity = self._analyze_region_connectivity(binary_mask, region_sizes)
            
            return SegmentationAnalysis(
                detected_regions=detected_regions,
                total_segmented_pixels=total_segmented_pixels,
                largest_region_size=largest_region_size,
                average_region_size=average_region_size,
                segmentation_quality=segmentation_quality.value,
                anatomical_coherence=anatomical_coherence,
                edge_sharpness=edge_sharpness,
                region_connectivity=region_connectivity
            )
            
        except Exception as e:
            logger.error(f"Failed to analyze segmentation masks: {e}")
            return SegmentationAnalysis(
                detected_regions=0,
                total_segmented_pixels=0,
                largest_region_size=0,
                average_region_size=0.0,
                segmentation_quality=SegmentationQuality.POOR.value,
                anatomical_coherence="error",
                edge_sharpness=0.0,
                region_connectivity={}
            )
    
    def _calculate_technical_score(self, parsed_data: Dict[str, Any]) -> float:
        """Calculate technical performance score (0.0-1.0)"""
        score = 0.5  # Base score
        
        # Model metadata completeness
        model_metadata = parsed_data.get("model_metadata", {})
        if model_metadata.get("model_architecture"):
            score += 0.1
        if model_metadata.get("medical_grade"):
            score += 0.1
        if model_metadata.get("preprocessing"):
            score += 0.05
        
        # Raw predictions quality
        raw_predictions = parsed_data.get("raw_predictions", [])
        if raw_predictions:
            score += 0.1
            if isinstance(raw_predictions, list) and len(raw_predictions) >= 5:
                score += 0.05  # Multi-class predictions
        
        # Confidence maps availability
        if parsed_data.get("confidence_maps") is not None:
            score += 0.15
        
        # Processing metadata
        processing_metadata = parsed_data.get("processing_metadata", {})
        if processing_metadata.get("prediction_shape"):
            score += 0.05
        if processing_metadata.get("medical_context"):
            score += 0.05
        
        return min(1.0, score)
    
    def _calculate_clinical_score(self, parsed_data: Dict[str, Any], analysis_context: Dict[str, Any]) -> float:
        """Calculate clinical relevance score (0.0-1.0)"""
        score = 0.5  # Base score
        
        # Medical context availability
        if analysis_context.get("patient_context"):
            score += 0.1
        if analysis_context.get("anatomical_location"):
            score += 0.1
        if analysis_context.get("clinical_history"):
            score += 0.1
        
        # Model medical specialization
        model_metadata = parsed_data.get("model_metadata", {})
        if model_metadata.get("medical_specialization") == "pressure_injury_detection":
            score += 0.15
        if model_metadata.get("medical_grade"):
            score += 0.1
        
        # Prediction medical relevance
        raw_predictions = parsed_data.get("raw_predictions", [])
        if raw_predictions and isinstance(raw_predictions, list):
            # Check for LPP staging predictions (0-4)
            if len(raw_predictions) == 5:
                score += 0.05
        
        return min(1.0, score)
    
    def _determine_performance_level(self, prediction_confidence: float, technical_score: float, clinical_score: float) -> ModelPerformanceLevel:
        """Determine overall model performance level"""
        
        overall_score = (prediction_confidence * 0.4) + (technical_score * 0.3) + (clinical_score * 0.3)
        
        if overall_score >= 0.9:
            return ModelPerformanceLevel.EXCELLENT
        elif overall_score >= 0.75:
            return ModelPerformanceLevel.GOOD
        elif overall_score >= 0.6:
            return ModelPerformanceLevel.ACCEPTABLE
        elif overall_score >= 0.4:
            return ModelPerformanceLevel.CONCERNING
        else:
            return ModelPerformanceLevel.POOR
    
    def _assess_processing_quality(self, parsed_data: Dict[str, Any]) -> str:
        """Assess data processing quality"""
        
        model_metadata = parsed_data.get("model_metadata", {})
        processing_metadata = parsed_data.get("processing_metadata", {})
        
        quality_indicators = 0
        
        # Preprocessing quality
        if model_metadata.get("preprocessing") == "monai_medical_transforms":
            quality_indicators += 1
        
        # Medical context
        if processing_metadata.get("medical_context"):
            quality_indicators += 1
        
        # Data completeness
        if parsed_data.get("confidence_maps") is not None:
            quality_indicators += 1
        
        # Metadata completeness
        if model_metadata.get("model_parameters"):
            quality_indicators += 1
        
        if quality_indicators >= 3:
            return "high"
        elif quality_indicators >= 2:
            return "good"
        elif quality_indicators >= 1:
            return "acceptable"
        else:
            return "poor"
    
    def _assess_medical_validity(self, parsed_data: Dict[str, Any], analysis_context: Dict[str, Any]) -> str:
        """Assess medical validity of predictions"""
        
        model_metadata = parsed_data.get("model_metadata", {})
        raw_predictions = parsed_data.get("raw_predictions", [])
        
        # Medical-grade model validation
        if not model_metadata.get("medical_grade", False):
            return "non_medical"
        
        # Medical specialization validation
        if model_metadata.get("medical_specialization") != "pressure_injury_detection":
            return "non_specialized"
        
        # Prediction format validation
        if not raw_predictions or not isinstance(raw_predictions, list):
            return "invalid_format"
        
        # Medical context validation
        if not analysis_context.get("patient_context"):
            return "insufficient_context"
        
        # All validations passed
        return "validated"
    
    def _assess_research_value(self, parsed_data: Dict[str, Any], technical_score: float, clinical_score: float) -> str:
        """Assess research value of the data"""
        
        research_score = (technical_score + clinical_score) / 2
        
        # Additional research value factors
        if parsed_data.get("confidence_maps") is not None:
            research_score += 0.1
        
        if parsed_data.get("model_metadata", {}).get("medical_grade"):
            research_score += 0.1
        
        if research_score >= 0.8:
            return "high"
        elif research_score >= 0.6:
            return "moderate"
        elif research_score >= 0.4:
            return "limited"
        else:
            return "low"
    
    def _count_connected_regions(self, binary_mask: np.ndarray) -> int:
        """Count connected regions in binary mask"""
        try:
            # Simple connected components analysis
            from scipy import ndimage
            labeled, num_regions = ndimage.label(binary_mask)
            return int(num_regions)
        except ImportError:
            # Fallback without scipy
            return 1 if np.any(binary_mask) else 0
    
    def _analyze_region_sizes(self, binary_mask: np.ndarray) -> List[int]:
        """Analyze sizes of detected regions"""
        try:
            from scipy import ndimage
            labeled, num_regions = ndimage.label(binary_mask)
            
            region_sizes = []
            for i in range(1, num_regions + 1):
                region_size = np.sum(labeled == i)
                region_sizes.append(int(region_size))
            
            return region_sizes
        except ImportError:
            # Fallback without scipy
            total_pixels = int(np.sum(binary_mask))
            return [total_pixels] if total_pixels > 0 else []
    
    def _assess_segmentation_quality(self, detected_regions: int, total_pixels: int, region_sizes: List[int]) -> SegmentationQuality:
        """Assess overall segmentation quality"""
        
        if detected_regions == 0 or total_pixels == 0:
            return SegmentationQuality.INVALID
        
        # Check for reasonable region sizes
        min_size = self.quality_thresholds['min_segmentation_size']
        valid_regions = sum(1 for size in region_sizes if size >= min_size)
        
        if valid_regions == 0:
            return SegmentationQuality.POOR
        elif valid_regions == detected_regions and detected_regions <= 3:
            return SegmentationQuality.PRECISE
        elif valid_regions >= detected_regions * 0.8:
            return SegmentationQuality.GOOD
        else:
            return SegmentationQuality.MODERATE
    
    def _assess_anatomical_coherence(self, binary_mask: np.ndarray, region_sizes: List[int]) -> str:
        """Assess anatomical coherence of segmentation"""
        
        if not region_sizes:
            return "no_regions"
        
        # Check for oversegmentation (too many small regions)
        small_regions = sum(1 for size in region_sizes if size < 50)
        if small_regions > 5:
            return "oversegmented"
        
        # Check for undersegmentation (one massive region)
        total_pixels = sum(region_sizes)
        largest_region = max(region_sizes)
        if largest_region > 0.8 * total_pixels and len(region_sizes) == 1:
            return "undersegmented"
        
        # Check for reasonable distribution
        if len(region_sizes) <= 3 and all(size >= 100 for size in region_sizes):
            return "coherent"
        else:
            return "fragmented"
    
    def _calculate_edge_sharpness(self, confidence_maps: np.ndarray) -> float:
        """Calculate edge sharpness metric"""
        try:
            # Calculate gradient magnitude
            grad_x = np.gradient(confidence_maps, axis=-1)
            grad_y = np.gradient(confidence_maps, axis=-2)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            
            # Average gradient magnitude as sharpness metric
            sharpness = float(np.mean(gradient_magnitude))
            return min(1.0, sharpness)
            
        except Exception:
            return 0.0
    
    def _analyze_region_connectivity(self, binary_mask: np.ndarray, region_sizes: List[int]) -> Dict[str, Any]:
        """Analyze connectivity of detected regions"""
        
        connectivity = {
            "total_regions": len(region_sizes),
            "largest_region_percentage": 0.0,
            "region_distribution": "unknown",
            "connectivity_score": 0.0
        }
        
        if not region_sizes:
            return connectivity
        
        total_pixels = sum(region_sizes)
        largest_region = max(region_sizes)
        
        connectivity["largest_region_percentage"] = (largest_region / total_pixels) * 100 if total_pixels > 0 else 0
        
        # Classify region distribution
        if len(region_sizes) == 1:
            connectivity["region_distribution"] = "single_region"
        elif len(region_sizes) <= 3:
            connectivity["region_distribution"] = "few_large_regions"
        elif len(region_sizes) <= 10:
            connectivity["region_distribution"] = "multiple_regions"
        else:
            connectivity["region_distribution"] = "many_small_regions"
        
        # Calculate connectivity score
        if connectivity["region_distribution"] == "single_region":
            connectivity["connectivity_score"] = 1.0
        elif connectivity["region_distribution"] == "few_large_regions":
            connectivity["connectivity_score"] = 0.8
        elif connectivity["region_distribution"] == "multiple_regions":
            connectivity["connectivity_score"] = 0.6
        else:
            connectivity["connectivity_score"] = 0.3
        
        return connectivity
    
    def _identify_uncertainty_areas(self, confidence_maps: np.ndarray) -> List[Dict[str, Any]]:
        """Identify areas of high uncertainty in confidence maps"""
        
        uncertainty_areas = []
        
        try:
            # Calculate local variance to identify uncertainty
            from scipy import ndimage
            
            # Calculate local standard deviation
            local_std = ndimage.generic_filter(confidence_maps, np.std, size=5)
            
            # Identify high variance areas
            high_variance_threshold = np.percentile(local_std, 90)
            uncertain_regions = local_std > high_variance_threshold
            
            # Find connected components of uncertain regions
            labeled, num_uncertain = ndimage.label(uncertain_regions)
            
            for i in range(1, min(num_uncertain + 1, 6)):  # Limit to top 5
                region_mask = labeled == i
                region_size = int(np.sum(region_mask))
                
                if region_size > 25:  # Minimum size threshold
                    # Calculate region center
                    coords = np.where(region_mask)
                    center_y = int(np.mean(coords[0]))
                    center_x = int(np.mean(coords[1]))
                    
                    uncertainty_areas.append({
                        "region_id": i,
                        "size_pixels": region_size,
                        "center_coordinates": [center_x, center_y],
                        "uncertainty_level": float(np.mean(local_std[region_mask])),
                        "confidence_variance": float(np.var(confidence_maps[region_mask]))
                    })
            
        except ImportError:
            # Fallback without scipy
            uncertainty_areas.append({
                "region_id": 1,
                "size_pixels": 0,
                "center_coordinates": [0, 0],
                "uncertainty_level": 0.5,
                "confidence_variance": 0.1
            })
        
        return uncertainty_areas
    
    async def _interpret_medical_findings(
        self,
        parsed_data: Dict[str, Any],
        model_assessment: ModelAssessment,
        analysis_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Interpret MONAI findings from medical perspective"""
        
        raw_predictions = parsed_data.get("raw_predictions", [])
        model_metadata = parsed_data.get("model_metadata", {})
        
        interpretation = {
            "lpp_staging_analysis": {},
            "medical_significance": "",
            "clinical_recommendations": [],
            "confidence_assessment": "",
            "diagnostic_value": "",
            "limitations": []
        }
        
        # Analyze LPP staging predictions
        if isinstance(raw_predictions, list) and len(raw_predictions) == 5:
            # MONAI predictions for LPP stages 0-4
            stage_confidences = {f"Stage_{i}": float(pred) for i, pred in enumerate(raw_predictions)}
            predicted_stage = max(stage_confidences, key=stage_confidences.get)
            max_confidence = max(stage_confidences.values())
            
            interpretation["lpp_staging_analysis"] = {
                "predicted_stage": predicted_stage,
                "stage_confidences": stage_confidences,
                "prediction_confidence": max_confidence
            }
            
            # Medical significance
            stage_num = int(predicted_stage.split("_")[1])
            if stage_num == 0:
                interpretation["medical_significance"] = "No pressure injury detected by MONAI analysis"
            elif stage_num == 1:
                interpretation["medical_significance"] = "Stage 1 pressure injury - non-blanchable erythema"
            elif stage_num == 2:
                interpretation["medical_significance"] = "Stage 2 pressure injury - partial thickness skin loss"
            elif stage_num == 3:
                interpretation["medical_significance"] = "Stage 3 pressure injury - full thickness skin loss"
            elif stage_num == 4:
                interpretation["medical_significance"] = "Stage 4 pressure injury - full thickness tissue loss"
            
            # Clinical recommendations based on staging
            if stage_num >= 3:
                interpretation["clinical_recommendations"].extend([
                    "URGENT: Immediate wound care specialist consultation required",
                    "Complete pressure offloading of affected area",
                    "Comprehensive wound assessment and documentation"
                ])
            elif stage_num >= 2:
                interpretation["clinical_recommendations"].extend([
                    "Implement immediate pressure relief measures",
                    "Enhanced wound care protocol",
                    "Consider specialist consultation"
                ])
            elif stage_num >= 1:
                interpretation["clinical_recommendations"].extend([
                    "Increase repositioning frequency",
                    "Apply pressure redistribution measures",
                    "Monitor for progression"
                ])
        
        # Confidence assessment
        if model_assessment.prediction_confidence >= 0.8:
            interpretation["confidence_assessment"] = "High confidence - reliable for clinical decision support"
        elif model_assessment.prediction_confidence >= 0.6:
            interpretation["confidence_assessment"] = "Moderate confidence - consider additional validation"
        else:
            interpretation["confidence_assessment"] = "Low confidence - human review strongly recommended"
        
        # Diagnostic value assessment
        if model_assessment.performance_level == "excellent":
            interpretation["diagnostic_value"] = "High diagnostic value - suitable for clinical decision support"
        elif model_assessment.performance_level == "good":
            interpretation["diagnostic_value"] = "Good diagnostic value - reliable clinical tool"
        elif model_assessment.performance_level == "acceptable":
            interpretation["diagnostic_value"] = "Acceptable diagnostic value - use with clinical correlation"
        else:
            interpretation["diagnostic_value"] = "Limited diagnostic value - human review required"
        
        # Identify limitations
        if not model_metadata.get("medical_grade"):
            interpretation["limitations"].append("Model not specifically validated for medical use")
        
        if model_assessment.prediction_confidence < 0.7:
            interpretation["limitations"].append("Low prediction confidence may affect reliability")
        
        if not analysis_context.get("patient_context"):
            interpretation["limitations"].append("Limited patient context for interpretation")
        
        return interpretation
    
    async def _calculate_quality_metrics(
        self,
        model_assessment: ModelAssessment,
        confidence_analysis: ConfidenceAnalysis,
        segmentation_analysis: SegmentationAnalysis
    ) -> Dict[str, float]:
        """Calculate comprehensive quality metrics"""
        
        return {
            "overall_quality_score": (model_assessment.technical_score + model_assessment.clinical_score) / 2,
            "prediction_reliability": model_assessment.prediction_confidence,
            "confidence_consistency": 1.0 - confidence_analysis.confidence_std,
            "segmentation_coherence": segmentation_analysis.region_connectivity.get("connectivity_score", 0.5),
            "medical_validity_score": 1.0 if model_assessment.medical_validity == "validated" else 0.5,
            "research_utility_score": 1.0 if model_assessment.research_value == "high" else 0.7 if model_assessment.research_value == "moderate" else 0.3,
            "technical_robustness": model_assessment.technical_score,
            "clinical_relevance": model_assessment.clinical_score
        }
    
    async def _generate_validation_findings(
        self,
        parsed_data: Dict[str, Any],
        model_assessment: ModelAssessment,
        medical_interpretation: Dict[str, Any]
    ) -> List[str]:
        """Generate validation findings and concerns"""
        
        findings = []
        
        # Performance validation
        if model_assessment.performance_level == "excellent":
            findings.append("âœ… Model demonstrates excellent performance across all metrics")
        elif model_assessment.performance_level == "poor":
            findings.append("âš ï¸ Model shows poor performance - validation concerns identified")
        
        # Medical validation
        if model_assessment.medical_validity == "validated":
            findings.append("âœ… Medical validation criteria met")
        else:
            findings.append("âš ï¸ Medical validation concerns identified")
        
        # Confidence validation
        if model_assessment.prediction_confidence >= 0.8:
            findings.append("âœ… High prediction confidence supports clinical reliability")
        elif model_assessment.prediction_confidence < 0.6:
            findings.append("âš ï¸ Low prediction confidence requires human validation")
        
        # Segmentation validation
        if parsed_data.get("confidence_maps") is not None:
            findings.append("âœ… Detailed segmentation data available for validation")
        else:
            findings.append("â„¹ï¸ Limited segmentation data for detailed validation")
        
        # Clinical interpretation validation
        if medical_interpretation.get("diagnostic_value", "").startswith("High"):
            findings.append("âœ… High diagnostic value confirmed")
        elif "Limited" in medical_interpretation.get("diagnostic_value", ""):
            findings.append("âš ï¸ Limited diagnostic value identified")
        
        return findings
    
    async def _generate_research_insights(
        self,
        parsed_data: Dict[str, Any],
        model_assessment: ModelAssessment,
        analysis_context: Dict[str, Any]
    ) -> List[str]:
        """Generate research insights from MONAI analysis"""
        
        insights = []
        
        # Model architecture insights
        model_metadata = parsed_data.get("model_metadata", {})
        architecture = model_metadata.get("model_architecture", "unknown")
        
        if architecture == "medical_sam":
            insights.append("ðŸ”¬ Medical SAM architecture shows promising segmentation capabilities for LPP detection")
        elif architecture == "densenet121":
            insights.append("ðŸ”¬ DenseNet121 provides stable classification performance for LPP staging")
        
        # Performance insights
        if model_assessment.technical_score >= 0.8 and model_assessment.clinical_score >= 0.8:
            insights.append("ðŸ“Š Strong correlation between technical and clinical performance metrics")
        
        # Confidence analysis insights
        confidence_maps = parsed_data.get("confidence_maps")
        if confidence_maps is not None:
            insights.append("ðŸŽ¯ Detailed confidence mapping enables uncertainty quantification for medical decisions")
        
        # Medical specialization insights
        if model_metadata.get("medical_grade"):
            insights.append("ðŸ¥ Medical-grade model shows enhanced performance for clinical applications")
        
        # Research value insights
        if model_assessment.research_value == "high":
            insights.append("ðŸ“š High research value data suitable for model validation studies")
        
        # Dataset insights
        if analysis_context.get("patient_context"):
            insights.append("ðŸ‘¥ Rich patient context enables comprehensive medical validation")
        
        return insights
    
    async def _generate_technical_recommendations(
        self,
        model_assessment: ModelAssessment,
        confidence_analysis: ConfidenceAnalysis,
        segmentation_analysis: SegmentationAnalysis
    ) -> List[str]:
        """Generate technical improvement recommendations"""
        
        recommendations = []
        
        # Performance recommendations
        if model_assessment.performance_level in ["concerning", "poor"]:
            recommendations.append("ðŸ”§ Consider model retraining or architecture optimization")
        
        # Confidence recommendations
        if confidence_analysis.confidence_std > 0.3:
            recommendations.append("ðŸ“Š High confidence variance suggests need for uncertainty calibration")
        
        if confidence_analysis.low_confidence_regions > confidence_analysis.high_confidence_regions:
            recommendations.append("âš¡ Model shows low confidence in many regions - consider additional training data")
        
        # Segmentation recommendations
        if segmentation_analysis.segmentation_quality in ["poor", "invalid"]:
            recommendations.append("ðŸŽ¯ Segmentation quality issues - review preprocessing and model architecture")
        
        if segmentation_analysis.anatomical_coherence == "oversegmented":
            recommendations.append("ðŸ” Oversegmentation detected - consider post-processing smoothing")
        elif segmentation_analysis.anatomical_coherence == "undersegmented":
            recommendations.append("ðŸ“ Undersegmentation detected - review model sensitivity settings")
        
        # Technical improvements
        if model_assessment.technical_score < 0.6:
            recommendations.append("âš™ï¸ Technical infrastructure improvements needed for robust performance")
        
        # Clinical improvements
        if model_assessment.clinical_score < 0.6:
            recommendations.append("ðŸ¥ Enhanced clinical context integration recommended")
        
        return recommendations
    
    async def _store_monai_review(self, result: MonaiReviewResult):
        """Store MONAI review result in database"""
        try:
            if not self.supabase.client:
                logger.warning("No database connection - MONAI review not stored")
                return
            
            review_data = {
                "review_id": result.review_id,
                "raw_output_id": result.raw_output_id,
                "token_id": result.token_id,
                "model_version": result.model_assessment.model_version,
                "model_architecture": result.model_assessment.model_architecture,
                "performance_level": result.model_assessment.performance_level,
                "prediction_confidence": result.model_assessment.prediction_confidence,
                "technical_score": result.model_assessment.technical_score,
                "clinical_score": result.model_assessment.clinical_score,
                "research_value": result.model_assessment.research_value,
                "confidence_analysis": {
                    "mean_confidence": result.confidence_analysis.mean_confidence,
                    "confidence_std": result.confidence_analysis.confidence_std,
                    "high_confidence_regions": result.confidence_analysis.high_confidence_regions,
                    "uncertainty_areas_count": len(result.confidence_analysis.uncertainty_areas)
                },
                "segmentation_analysis": {
                    "detected_regions": result.segmentation_analysis.detected_regions,
                    "segmentation_quality": result.segmentation_analysis.segmentation_quality,
                    "anatomical_coherence": result.segmentation_analysis.anatomical_coherence
                },
                "medical_interpretation": result.medical_interpretation,
                "quality_metrics": result.quality_metrics,
                "validation_findings": result.validation_findings,
                "research_insights": result.research_insights,
                "technical_recommendations": result.technical_recommendations,
                "created_at": result.review_timestamp.isoformat(),
                "hipaa_compliant": True,
                "reviewer_agent": result.reviewer_agent
            }
            
            # Insert into monai_reviews table
            self.supabase.client.table("monai_reviews").insert(review_data).execute()
            
            logger.info(f"Stored MONAI review {result.review_id}")
            
        except Exception as e:
            logger.error(f"Failed to store MONAI review: {e}")
    
    def _serialize_review_result(self, result: MonaiReviewResult) -> Dict[str, Any]:
        """Serialize review result for JSON response"""
        return {
            "review_id": result.review_id,
            "raw_output_id": result.raw_output_id,
            "token_id": result.token_id,
            "model_assessment": {
                "model_version": result.model_assessment.model_version,
                "model_architecture": result.model_assessment.model_architecture,
                "performance_level": result.model_assessment.performance_level,
                "prediction_confidence": result.model_assessment.prediction_confidence,
                "technical_score": result.model_assessment.technical_score,
                "clinical_score": result.model_assessment.clinical_score,
                "research_value": result.model_assessment.research_value
            },
            "confidence_analysis": {
                "mean_confidence": result.confidence_analysis.mean_confidence,
                "max_confidence": result.confidence_analysis.max_confidence,
                "min_confidence": result.confidence_analysis.min_confidence,
                "confidence_std": result.confidence_analysis.confidence_std,
                "high_confidence_regions": result.confidence_analysis.high_confidence_regions,
                "low_confidence_regions": result.confidence_analysis.low_confidence_regions,
                "uncertainty_areas": result.confidence_analysis.uncertainty_areas
            },
            "segmentation_analysis": {
                "detected_regions": result.segmentation_analysis.detected_regions,
                "total_segmented_pixels": result.segmentation_analysis.total_segmented_pixels,
                "segmentation_quality": result.segmentation_analysis.segmentation_quality,
                "anatomical_coherence": result.segmentation_analysis.anatomical_coherence,
                "edge_sharpness": result.segmentation_analysis.edge_sharpness
            },
            "medical_interpretation": result.medical_interpretation,
            "quality_metrics": result.quality_metrics,
            "validation_findings": result.validation_findings,
            "research_insights": result.research_insights,
            "technical_recommendations": result.technical_recommendations,
            "review_timestamp": result.review_timestamp.isoformat(),
            "hipaa_compliant": result.hipaa_compliant
        }
    
    async def _update_review_stats(self, processing_time: float, result: MonaiReviewResult):
        """Update agent statistics"""
        self.stats['reviews_completed'] += 1
        
        # Update average processing time
        current_avg = self.stats['avg_review_time']
        total_reviews = self.stats['reviews_completed']
        self.stats['avg_review_time'] = (
            (current_avg * (total_reviews - 1) + processing_time) / total_reviews
        )
        
        # Count performance levels
        if result.model_assessment.performance_level == "excellent":
            self.stats['excellent_performance_cases'] += 1
        elif result.model_assessment.performance_level in ["concerning", "poor"]:
            self.stats['concerning_cases'] += 1
        
        # Count research insights
        if result.research_insights:
            self.stats['research_insights_generated'] += len(result.research_insights)
        
        # Count technical issues
        if result.technical_recommendations:
            self.stats['technical_issues_identified'] += 1
    
    # Additional handler methods for other actions (similar structure to risk agent)
    async def _handle_performance_assessment(self, message: AgentMessage) -> AgentResponse:
        """Handle model performance assessment requests"""
        # Implementation similar to other handlers
        return AgentResponse(success=True, message="Performance assessment completed", data={})
    
    async def _handle_confidence_analysis(self, message: AgentMessage) -> AgentResponse:
        """Handle confidence analysis requests"""
        # Implementation similar to other handlers
        return AgentResponse(success=True, message="Confidence analysis completed", data={})
    
    async def _handle_segmentation_review(self, message: AgentMessage) -> AgentResponse:
        """Handle segmentation review requests"""
        # Implementation similar to other handlers
        return AgentResponse(success=True, message="Segmentation review completed", data={})
    
    async def _handle_research_insights(self, message: AgentMessage) -> AgentResponse:
        """Handle research insights generation requests"""
        # Implementation similar to other handlers
        return AgentResponse(success=True, message="Research insights generated", data={})
    
    async def _handle_medical_validation(self, message: AgentMessage) -> AgentResponse:
        """Handle medical validation requests"""
        # Implementation similar to other handlers
        return AgentResponse(success=True, message="Medical validation completed", data={})
    
    async def _handle_capabilities_request(self, message: AgentMessage) -> AgentResponse:
        """Handle capabilities request"""
        return AgentResponse(
            success=True,
            message="MONAI Review Agent capabilities",
            data={
                "capabilities": self.get_capabilities(),
                "quality_thresholds": self.quality_thresholds,
                "supported_analyses": ["confidence_maps", "segmentation_masks", "model_performance", "medical_validation"],
                "performance_levels": [level.value for level in ModelPerformanceLevel],
                "segmentation_qualities": [quality.value for quality in SegmentationQuality],
                "agent_type": "monai_review",
                "batman_tokenization": True,
                "statistics": self.stats
            }
        )
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get agent health status"""
        return {
            "agent_id": self.agent_id,
            "status": "healthy",
            "raw_outputs_client_available": self.raw_outputs_client is not None,
            "database_connected": self.supabase.client is not None,
            "capabilities_count": len(self.get_capabilities()),
            "reviews_completed": self.stats['reviews_completed'],
            "excellent_cases": self.stats['excellent_performance_cases'],
            "research_insights_generated": self.stats['research_insights_generated'],
            "last_review": datetime.now().isoformat(),
            "tokenization_compliant": True
        }


# Export for ADK integration
__all__ = ["MonaiReviewAgent", "ModelPerformanceLevel", "SegmentationQuality", "MonaiReviewResult"]